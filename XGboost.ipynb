{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#read data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국가를 대륙으로 매핑하는 딕셔너리\n",
    "country_continent_dict = {\n",
    " 'US': 'US',\n",
    " 'Cuba': 'North America',\n",
    " 'Portugal': 'Europe',\n",
    " 'Mexico': 'North America',\n",
    " 'Unknown': 'US',\n",
    " 'Puerto-Rico': 'North America',\n",
    " 'Germany': 'Europe',\n",
    " 'Japan': 'Asia',\n",
    " 'Poland': 'Europe',\n",
    " 'Columbia': 'South America',\n",
    " 'Philippines': 'Asia',\n",
    " 'Italy': 'Europe',\n",
    " 'Trinadad&Tobago': 'South America',\n",
    " 'England': 'Europe',\n",
    " 'South Korea': 'Asia',\n",
    " 'Iran': 'Asia',\n",
    " 'France': 'Europe',\n",
    " 'India': 'Asia',\n",
    " 'China': 'Asia',\n",
    " 'Dominican-Republic': 'North America',\n",
    " 'Scotland': 'Europe',\n",
    " 'Ecuador': 'South America',\n",
    " 'Nicaragua': 'North America',\n",
    " 'Peru': 'South America',\n",
    " 'Cambodia': 'Asia',\n",
    " 'Canada': 'North America',\n",
    " 'Jamaica': 'North America',\n",
    " 'Vietnam': 'Asia',\n",
    " 'Hong Kong': 'Asia',\n",
    " 'Thailand': 'Asia',\n",
    " 'Haiti': 'North America',\n",
    " 'Guatemala': 'North America',\n",
    " 'Laos': 'Asia',\n",
    " 'Yugoslavia': 'Europe',\n",
    " 'Ireland': 'Europe',\n",
    " 'El-Salvador': 'North America',\n",
    " 'Panama': 'North America',\n",
    " 'Honduras': 'North America',\n",
    " 'Greece': 'Europe',\n",
    " 'Outlying-U S (Guam USVI etc)': 'US',\n",
    " 'Hungary': 'Europe',\n",
    " 'Taiwan': 'Asia',\n",
    " 'Holand-Netherlands': 'Europe'\n",
    "}\n",
    "\n",
    "# 업데이트할 열 목록: 본인 출신국가, 엄마 출신국가, 아빠 출신국가\n",
    "columns_to_update = ['Birth_Country', 'Birth_Country (Mother)', 'Birth_Country (Father)']\n",
    "\n",
    "# 각 열에 대해 국가를 대륙으로 매핑\n",
    "for column in columns_to_update:\n",
    "    train_data[column] = train_data[column].map(country_continent_dict)\n",
    "\n",
    "# Remove rows where 'Age' is below 17 or above 75\n",
    "train_data = train_data[train_data['Age'].between(17, 75)]\n",
    "\n",
    "# Remove rows with 'Employment Status' as 'Not Working' or 'Seeking Full-Time'\n",
    "train_data = train_data[~train_data['Employment_Status'].isin(['Not Working', 'Seeking Full-Time'])]\n",
    "\n",
    "# Drop the 'Gains', 'Losses', 'Dividends', 'Household_Status', 'Income_Status' columns\n",
    "train_data.drop(['Gains', 'Losses', 'Dividends', 'Household_Status', 'Income_Status'], axis=1, inplace=True)\n",
    "\n",
    "# Map 'Gender' values from 'M' and 'F' to 0 and 1, respectively\n",
    "train_data['Gender'] = train_data['Gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Consolidate education levels and rename as specified\n",
    "education_map = {\n",
    "    'High graduate': 'High', 'High Senior': 'High', \n",
    "    'High Junior': 'High', 'High Sophomore': 'High',\n",
    "    'Elementary (5-6)': 'Elementary(1-6)', 'Elementary (1-4)': 'Elementary(1-6)',\n",
    "    'Kindergarten': 'Baby', 'Children': 'Baby'\n",
    "}\n",
    "train_data['Education_Status'] = train_data['Education_Status'].replace(education_map)\n",
    "columns=[\n",
    "    'Education_Status',\n",
    "    'Employment_Status',\n",
    "    'Industry_Status',\n",
    "    'Occupation_Status',\n",
    "    'Race',\n",
    "    'Hispanic_Origin',\n",
    "    'Martial_Status',\n",
    "    'Household_Summary',\n",
    "    'Citizenship',\n",
    "    'Birth_Country',\n",
    "    'Birth_Country (Father)',\n",
    "    'Birth_Country (Mother)',\n",
    "    'Tax_Status'\n",
    "]\n",
    "edit_train_data=pd.get_dummies(train_data,columns=columns,dtype=int)\n",
    "edit_train_data = edit_train_data.drop(columns=['ID'])\n",
    "edit_train_data = edit_train_data.drop(columns=['Income'])\n",
    "edit_train_data.to_csv(\"editedTrain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 데이터 불러오기 (이 코드는 예시이므로 데이터를 실제로 불러올 수 없으므로 임의의 데이터로 대체합니다.)\n",
    "# edit_train_data와 train_data를 각각 X와 y로 가정합니다.\n",
    "X = edit_train_data\n",
    "y = train_data['Income']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost 모델 생성 및 학습\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 그리드 서치를 위한 파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 확인\n",
    "best_params = grid_search.best_params_\n",
    "print(\"최적의 하이퍼파라미터:\", best_params)\n",
    "\n",
    "# 최적의 모델 가져오기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"KNN 모델 성능:\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"EditedTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_to_zero = testData[(testData[\"Age\"] < 17) | \n",
    "                      (testData[\"Age\"] > 75) | \n",
    "                      (testData[\"Employment_Status\"] == \"Not Working\") | \n",
    "                      (testData[\"Employment_Status\"] == \"Seeking Full-Time\")].index\n",
    "\n",
    "# 'df_encoded'는 훈련 데이터에 대해 이미 원핫 인코딩이 수행된 DataFrame입니다.\n",
    "# 'train_cols'는 원핫 인코딩된 훈련 데이터의 열 순서입니다.\n",
    "train_cols = edit_train_data.columns\n",
    "\n",
    "# 'columns' 리스트에 지정된 열에 대해 testData 데이터프레임을 원핫 인코딩합니다.\n",
    "edited_testData = pd.get_dummies(testData, columns=columns, dtype=int)\n",
    "\n",
    "# 훈련 데이터에만 있는 열을 찾습니다.\n",
    "missing_cols = set(train_cols) - set(edited_testData.columns)\n",
    "\n",
    "# 훈련 데이터에만 있는 열을 테스트 데이터에 추가하고, 해당 열의 값을 0으로 설정합니다.\n",
    "for col in missing_cols:\n",
    "    edited_testData[col] = 0\n",
    "\n",
    "# 테스트 데이터에서 훈련 데이터에 없는 열을 찾습니다.\n",
    "extra_cols = set(edited_testData.columns) - set(train_cols)\n",
    "\n",
    "# 테스트 데이터에서 훈련 데이터에 없는 열을 제거합니다.\n",
    "edited_testData = edited_testData.drop(columns=extra_cols)\n",
    "\n",
    "# 테스트 데이터의 열 순서를 훈련 데이터의 열 순서와 동일하게 재정렬합니다.\n",
    "edited_testData = edited_testData[train_cols]\n",
    "\n",
    "# 이제 'edited_testData'는 원핫 인코딩된 테스트 데이터이며, 열 순서가 'df_encoded'와 일치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Xgboost = grid_search.predict(edited_testData) \n",
    "for i in range(len(y_pred_Xgboost)):\n",
    "    if i in row_to_zero:\n",
    "        y_pred_Xgboost[i]=0\n",
    "    if y_pred_Xgboost<0:\n",
    "        y_pred_Xgboost[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 생성\n",
    "ids = [f'TEST_{i:04d}' for i in range(len(y_pred_Xgboost))]\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Income': y_pred_Xgboost\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv('submissionFileDNN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
